---
title: "dbplyrでデータサイエンス100本ノック(構造化データ加工編)."
author: "Shena"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
description: "This is a minimal example of using
  the bookdown package to write a book."
github-repo: 'Shena4746/datascience-100knocks-preprocess-R'
---

```{r setup, eval = TRUE, include=FALSE}
rm(list = ls())
gc(reset = TRUE)
gc(reset = TRUE)
knitr::opts_chunk$set(eval = TRUE, echo = TRUE, warning = FALSE)
```

# 前置き

## 概要
このドキュメントは, [データサイエンス100本ノック（構造化データ加工編）](https://github.com/The-Japan-DataScientist-Society/100knocks-preprocess) を R で解いた記録. dbplyr パッケージを利用して, 手元にデータをダウンロードせず, できるだけローカルの計算資源に依存しない方針をとる. なお, 全問の回答は載せていない. 特に, SQL の方が楽にできる問題や公式回答と似た回答になった問題の多くはスキップしている.

以下の記事は大変参考にさせていただきました. 公開に感謝します.
[【R】データサイエンス100本ノック（構造化データ加工編）をtidyverseでやった](https://qiita.com/eitsupi/items/ae0476605cbaa3b04fc7)

## dbplyr とは

詳細は以下に貼る公式ドキュメントや解説記事に譲り, ここでは大雑把に書く. dbplyr とは, dplyr の文法で書いた加工処理を SQL クエリに翻訳して実行し, その結果を返してくれるパッケージ. 

- [Introduction to dbplyr](https://dbplyr.tidyverse.org/articles/dbplyr.html)
- [巨大なデータがSQLサーバーにあるときに、Rでどう立ち向かうかマニュアル：dbplyrパッケージを中心として](https://yutatoyama.github.io/note/intro_R_for_SQL.html)

手元にデータをダウンロードしようとしなければ, SQL の場合と同様に, クエリの実行コストはサーバー側が持ってくれる. dbplyr で SQL に翻訳可能なコードのみ利用可能. したがって, 手元にデータを直接ダウンロードした場合に比べて, 必然的に道具立ては少なくなる. なお, この翻訳可能性は個別のコード単位で決定されるものであり, パッケージ単位で決まっているわけではない. この翻訳問題を回避するには, `dplyr::collect()` を使ってクエリ実行後の実データをダウンロードする必要があるが, それが一般に可能なのは `summarise()` などでデータサイズが十分に小さくなった場合であろう.

`dplyr::collect()` については dplyr [公式ドキュメント](https://dplyr.tidyverse.org/reference/compute.html) 参照. 蛇足ながら, 関連項目として, `dplyr::compute()`, `dplyr::copy_to` あたりにもよくお世話になる. 

\newpage