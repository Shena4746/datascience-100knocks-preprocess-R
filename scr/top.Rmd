---
title: "dbplyrでデータサイエンス100本ノック(構造化データ加工編)."
author: "Shena"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
description: "This is a minimal example of using
  the bookdown package to write a book."
github-repo: 'Shena4746/datascience-100knocks-preprocess-R'
---

```{r setup, eval = TRUE, include=FALSE}
rm(list = ls())
gc(reset = TRUE)
gc(reset = TRUE)
knitr::opts_chunk$set(eval = TRUE, echo = TRUE, warning = FALSE)
```

# 前置き

## 概要
このドキュメントは, [データサイエンス100本ノック（構造化データ加工編）](https://github.com/The-Japan-DataScientist-Society/100knocks-preprocess) を R で解いた記録. dbplyr パッケージを利用して, 手元にデータをダウンロードせず, できるだけローカルの計算資源に依存しない方針をとる. なお, 全問の回答は載せていない. 特に, SQL の方が楽にできる問題や公式回答と似た回答になった問題の多くはスキップしている.

以下の記事は大変参考にさせていただきました. 公開に感謝します.
[【R】データサイエンス100本ノック（構造化データ加工編）をtidyverseでやった](https://qiita.com/eitsupi/items/ae0476605cbaa3b04fc7)

## dbplyr とは

詳細は \@ref(references) References や以下の文献に譲り, ここでは大雑把に書く. dbplyr とは, dplyr の文法で書いた加工処理を接続先に合わせた適切な SQL クエリに翻訳して実行し, DBI などの DB バックエンドパッケージと連携して, 実行結果を返してくれるパッケージ. SQL と同様に, 実際の計算はサーバー側で行い, 実行結果 (に対する参照) が手元に返される.

- [Introduction to dbplyr](https://dbplyr.tidyverse.org/articles/dbplyr.html)
- [巨大なデータがSQLサーバーにあるときに、Rでどう立ち向かうかマニュアル：dbplyrパッケージを中心として](https://yutatoyama.github.io/note/intro_R_for_SQL.html)

SQL への翻訳を挟むので, dbplyr で利用可能な R コードは, SQL に翻訳可能なものに限られる. 必然的に, 手元にデータを直接ダウンロードした場合に比べて, 道具立ては少なくなる. なお, この翻訳可能性は個別のコード単位で決定されるものであり, パッケージ単位で決まっているわけではない. この翻訳問題を回避するには, `dplyr::collect()` を使ってクエリ実行後の実データをローカルマシンにダウンロードする必要があるが, それが一般に可能なのは `summarise()` などでデータサイズが十分に小さくなった場合であろう.

`dplyr::collect()` については dplyr [公式ドキュメント](https://dplyr.tidyverse.org/reference/compute.html) 参照.